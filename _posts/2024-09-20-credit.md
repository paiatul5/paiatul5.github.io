---
layout: post
title: Predicting Credit Card Delinquency using Machine Learning
image: "/posts/credit_card.png"
tags: [Classification, Machine Learning, Python, Pipelines]
---

# Credit Card Delinquency Prediction using ML
By Atul Pai

Please refer to the github repository fot detailed power point slides and notebook for reference

This project is based on Kaggle competition 'Give Me Some Credit'.

Banks play a crucial role in market economies. They decide who can get finance and on what terms and can make or break investment decisions. For markets and society to function, individuals and companies need access to credit. 

Credit scoring algorithms, which make a guess at the probability of default, are the method banks use to determine whether or not a loan should be granted. This competition requires participants to improve on the state of the art in credit scoring, by predicting the probability that somebody will experience financial distress in the next two years.

The evaluation metric AUC for the cometition. However, I've considered the problem statement to be to build a classifier that serves as a first pass to help analysts weed out probable delinquent customers. Model is intended to be used in conjunction with analysts' expertise, which would consider factors considered beyond the data in the model.

## Table of Contents
1. [What is Credit Delinquency?](#what-is-credit-delinquency)
2. [Why Does It Matter to Financial Institutions?](#why-does-it-matter-to-financial-institutions)
3. [Dataset](#dataset)
4. [Metric of Consideration](#metric-of-consideration)
5. [Models](#models)
6. [Results](#results)
7. [Final Model: XGBoost with Oversampling](#final-model-xgboost-with-oversampling)
8. [Local Interpretability (LIME)](#local-interpretability-lime)
9. [Deep Learning](#deep-learning)

---

## <a id="what-is-credit-delinquency"></a>What is Credit Delinquency?
- **Delinquency**: Borrower is behind on payments (typically 60 days).
- **Default**: When delinquency extends beyond a specified period (typically 9 months).

## <a id="why-does-it-matter-to-financial-institutions"></a>Why Does It Matter to Financial Institutions?
### Reasons to Monitor:
- **Macro Factors**: Loan delinquencies can lead to financial crises.
- **Reputation**: Delinquency rates impact a bank's image with shareholders.
- **Operational Costs**: Increased collection costs and capital loss.

### Factors Used to Predict Delinquency:
- Credit Score/FICO Score
- Interest Rate
- Debt-to-income ratio
- Borrowerâ€™s revolving balance
- Utilization rate of revolving line
- Payment history (30+ days overdue)

## <a id="dataset"></a>Dataset
- **Source**: Kaggle Competition: "Give Me Some Credit"
- **Goal**: Predict if an applicant will be delinquent in the next 2 years.
- **Records**: 150,000
  

## <a id="metric-of-consideration"></a>Metric of Consideration:
- Optimized for **Class 1 recall** to capture as many delinquencies as possible, minimizing false negatives.
- **Drawback**: Higher false positives, leading to additional work.

## <a id="models"></a>Models:
### Baseline:
- **XGBoost** with no oversampling.

### Oversampling Models:
1. **Logistic Regression**: Optimized using oversampling.
2. **Random Forest**: Used oversampling with tuning of hyperparameters.
3. **XGBoost**: Employed oversampling and hyperparameter tuning.

## <a id="results"></a>Results:
- The final **XGBoost model** achieved a **recall score of 78%** for predicting delinquent accounts.
- This means that out of all delinquent accounts, the model successfully identified 78%.
- However, **21% of flagged accounts** were false positives, meaning that the model predicted them to be delinquent, but they were not.
- The model flagged **25% of the total records** as potentially delinquent. Focusing on these flagged records helps to catch 78% of delinquencies&#8203;:contentReference[oaicite:0]{index=0}.

## <a id="final-model-xgboost-with-oversampling"></a>Final Model: XGBoost with Oversampling
- **Recall Score**: 78% for Class 1 (delinquent accounts).
- **Drawback**: 21% of flagged accounts are false positives.

## <a id="local-interpretability-lime"></a>Local Interpretability (LIME):
- Analyzed instances where the model was correct and incorrect in predicting delinquency.

## <a id="deep-learning"></a>Deep Learning:
- **Architecture 1**: 8 nodes in first and second layers.
- **Architecture 2**: 16 nodes in first and second layers.
- Both used all features and oversampling.
